{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefc0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8496beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df = pd.read_csv('CNN_Articels_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1ccd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels= ['Index', 'Headline', 'Author', 'Date published', 'Section',\n",
    "                 'Url', 'Keywords', 'Second headline', 'Article text'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682c1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['Description'].tolist()\n",
    "labels = df['Category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d7dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the test set into dev and test sets (50% dev, 50% test)\n",
    "dev_texts, test_texts, dev_labels, test_labels = train_test_split(test_texts, test_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c077ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained tokenizer and model\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2e351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input texts\n",
    "tokenized_train_texts = tokenizer(train_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "tokenized_dev_texts = tokenizer(dev_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "tokenized_test_texts = tokenizer(test_texts, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the labels from all splits to ensure all classes are known\n",
    "encoder.fit(train_labels + dev_labels + test_labels)\n",
    "\n",
    "# Transform labels to integers\n",
    "train_labels_int = encoder.transform(train_labels)\n",
    "\n",
    "dev_labels_int = encoder.transform(dev_labels)\n",
    "\n",
    "test_labels_int = encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc857f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer labels to tensors\n",
    "train_labels = torch.tensor(train_labels_int)\n",
    "\n",
    "dev_labels = torch.tensor(dev_labels_int)\n",
    "\n",
    "test_labels = torch.tensor(test_labels_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d07374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "weight_decay = 1e-4\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12c2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets for train, dev, and test sets\n",
    "train_dataset = TensorDataset(tokenized_train_texts['input_ids'], tokenized_train_texts['attention_mask'], train_labels)\n",
    "\n",
    "dev_dataset = TensorDataset(tokenized_dev_texts['input_ids'], tokenized_dev_texts['attention_mask'], dev_labels)\n",
    "\n",
    "test_dataset = TensorDataset(tokenized_test_texts['input_ids'], tokenized_test_texts['attention_mask'], test_labels)\n",
    "\n",
    "\n",
    "# Create DataLoaders for train, dev, and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size= batch_size, shuffle= True)\n",
    "\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size= batch_size, shuffle= False)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size= batch_size, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942b5152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model for sequence classification\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=6)\n",
    "\n",
    "# Freeze parameters\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9789f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer for training the softmax layer\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr= learning_rate, weight_decay= weight_decay)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c118d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adda39e8238147c28943f3b5e1da30fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer= optimizer,\n",
    "    num_warmup_steps= 0,\n",
    "    num_training_steps= num_training_steps,\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03faf7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch No. : 0, Devset Accuracy : 0.71814, Devset f1_score : 0.68638, Average loss: 0.84379\n",
      "epoch No. : 1, Devset Accuracy : 0.73529, Devset f1_score : 0.70395, Average loss: 0.80381\n",
      "epoch No. : 2, Devset Accuracy : 0.73039, Devset f1_score : 0.69952, Average loss: 0.80934\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_dev_accuracy = 0.0\n",
    "best_model_state_dict = None\n",
    "Validation_results= []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, batch_labels = batch\n",
    "        \n",
    "        input_ids= input_ids.to(device)\n",
    "        attention_mask= attention_mask.to(device)\n",
    "        batch_labels= batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids= input_ids, attention_mask= attention_mask, labels= batch_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #### to show progress_bar\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "        \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    dev_correct = 0\n",
    "    total_dev = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss_epoch= []\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader:\n",
    "            input_ids, attention_mask, batch_labels = batch\n",
    "            \n",
    "            input_ids= input_ids.to(device)\n",
    "            attention_mask= attention_mask.to(device)\n",
    "            batch_labels= batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            # Append true labels and predicted labels for later use\n",
    "            y_true.extend(batch_labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            loss_epoch.append(loss)\n",
    "        \n",
    "    # Calculate accuracy and F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate the average loss\n",
    "    loss_epoch_np = [tensor.cpu().detach().numpy() for tensor in loss_epoch]\n",
    "    average_loss= np.mean(loss_epoch_np)\n",
    "    print(f'epoch No. : {epoch}, Devset Accuracy : {round(accuracy,5)}, Devset f1_score : {round(f1,5)}, Average loss: {round(average_loss.tolist(),5)}')\n",
    "    \n",
    "    Validation_results.append([accuracy, f1, average_loss])\n",
    "    \n",
    "    if accuracy > best_dev_accuracy:\n",
    "        best_dev_accuracy = accuracy\n",
    "        # Save the best model (optional)\n",
    "        best_model_state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b60159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Testset Results\n",
    "data = {\n",
    "    'Validation_results': Validation_results,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('Model-3_Validation_results.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1a285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model state dict\n",
    "if best_model_state_dict is not None:\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    # Define the directory path to save the model\n",
    "    save_path = 'Model-3.pth'  \n",
    "\n",
    "    # Save the model state dictionary and other relevant information\n",
    "    torch.save({\n",
    "        'model_state_dict': best_model_state_dict,\n",
    "        'tokenizer': tokenizer  \n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d22992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy: 0.71569 , Testset F1 score: 0.68111, Average loss: 0.9027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "model.eval()\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "loss_epoch= []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, batch_labels = batch\n",
    "        \n",
    "        input_ids= input_ids.to(device)\n",
    "        attention_mask= attention_mask.to(device)\n",
    "        batch_labels= batch_labels.to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        # Append true labels and predicted labels for later use\n",
    "        y_true_test.extend(batch_labels.tolist())\n",
    "        y_pred_test.extend(predicted.tolist())\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(logits, batch_labels)\n",
    "        loss_epoch.append(loss)\n",
    "\n",
    "# Calculate accuracy and F1 score for the test set\n",
    "test_accuracy = accuracy_score(y_true_test, y_pred_test)\n",
    "test_f1 = f1_score(y_true_test, y_pred_test, average='weighted')\n",
    "\n",
    "# Calculate the average loss\n",
    "loss_epoch_np = [tensor.cpu().detach().numpy() for tensor in loss_epoch]\n",
    "average_loss= np.mean(loss_epoch_np)\n",
    "\n",
    "print(f\"Testset accuracy: {round(test_accuracy,5)} , Testset F1 score: {round(test_f1,5)}, Average loss: {round(average_loss.tolist(),5)}\")\n",
    "Test_results= [test_accuracy, test_f1, average_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "814fa811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Testset Results\n",
    "data = {\n",
    "    'Test_results': Test_results\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('Model-3_Test_results.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0f2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
